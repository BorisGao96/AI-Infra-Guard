info:
  name: llamafactory
  cve: CVE-2025-53002
  summary: LLaMA-Factory allows Code Injection through improper vhead_file safeguards
  details: |
    A critical remote code execution vulnerability was discovered during the Llama Factory training process. 
    This vulnerability arises because the `vhead_file` is loaded without proper safeguards, allowing malicious attackers to execute arbitrary malicious code on the host system simply by passing a malicious `Checkpoint path` parameter through the `WebUI` interface. 
    The root cause is that the `vhead_file` argument is loaded without the secure parameter `weights_only=True`. 
    In torch versions <2.6, the default setting is `weights_only=False`, and Llama Factory's `setup.py` only requires `torch>=2.0.0`.
    Affected versions are Llama Factory versions <=0.9.3.
  cvss: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:H
  severity: HIGH
  security_advise: |
    1. Upgrade to Llama Factory version > 0.9.3
    2. Ensure `torch.load()` is called with `weights_only=True` to prevent arbitrary code execution
    3. Validate and sanitize all `Checkpoint path` inputs in the WebUI
  rule: version <= "0.9.3"
  references:
    - https://github.com/hiyouga/LLaMA-Factory/security/advisories/GHSA-xj56-p8mm-qmxj
    - https://nvd.nist.gov/vuln/detail/CVE-2025-53002
    - https://github.com/hiyouga/LLaMA-Factory/commit/bb7bf51554d4ba8432333c35a5e3b52705955ede
    - https://github.com/hiyouga/LLaMA-Factory